[project]
name = "kv-caching-profiler"
version = "0.1.0"
description = "Memory profiling framework for on-device LLM runtimes"
readme = "README.md"
requires-python = ">=3.8"
license = { text = "MIT" }
authors = [
    { name = "Research Project", email = "" }
]
keywords = ["llm", "memory-profiling", "kv-cache", "ollama", "llama.cpp", "webllm", "on-device-llm"]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Science/Research",
    "Topic :: Scientific/Engineering",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.8",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
]

dependencies = [
    "psutil>=5.9.0",
    "requests>=2.31.0",
]

[project.optional-dependencies]
analysis = [
    "pandas>=2.0.0",
    "matplotlib>=3.7.0",
]

# Note: Scripts are standalone and run directly, not as entry points
# Run with: python memory_profiler.py, python run_ollama.py, etc.

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = []
include = [
    "experiments/**",
    "profiling/**",
    "inputs/**",
    "legacy/**",
    "README.md",
]

[tool.uv]
# Dependency groups can be added here if needed
# [dependency-groups]
# dev = []

[tool.uv.sources]
# If you need to pin specific sources, add them here
